# PixelStitch: Structure-Preserving Pixel-Wise Bidirectional Warps for Unsupervised Image Stitching

Official codes for ICCV 2025 paper [PixelStitch: Structure-Preserving Pixel-Wise Bidirectional Warps for Unsupervised Image Stitching](https://openaccess.thecvf.com/content/ICCV2025/papers/Jin_PixelStitch_Structure-Preserving_Pixel-Wise_Bidirectional_Warps_for_Unsupervised_Image_Stitching_ICCV_2025_paper.pdf).

# Update

- [x] The inference code and model weight of *PixelStitch* are now released!
- [ ] The training code is currently not provided.

# Usage

This repository only contains the pixel-wise warp stage of *PixelStitch* and a pre-computation of homography is needed. The homography should be presented in the form of `*.npy` numpy arrays shaped $(4, 2)$, which gives the difference between the corner coordinates of the source image and the warped one (e.g. if the image is $512(W) \times 256(H)$ and after warping the corner coordinates become $[[50, -6], [576, -62], [64, 227], [580, 228]]$, then the homography array should be $[[50, -6], [576, -62], [64, 227], [580, 228]] - [[0, 0], [512, 0], [0, 256], [512, 256]] = [[50,  -6], [64, -62], [64, -29], [68, -28]]$). By default, the homography arrays are named the same as each image files and put in `<data_root>/homo`.

# Dataset

We use [UDIS-D dataset](https://github.com/nie-lang/UnsupervisedDeepImageStitching) to train and evaluate our method. The homography arrays used for UDIS-D dataset are provided in `dataset/` which are generated by [UDIS++](https://github.com/nie-lang/UDIS2). The data other than the homography arrays should be arranged like UDIS-D.

# Evaluation

Use `test.py` to evaluate *PixelStitch* on your dataset.

```shell
python test.py --data-root=/path/to/your/dataset --out-dir=/path/to/save/outputs --save-path=/path/to/model/checkpoint
```

The model checkpoint is provided in `checkpoints/ckpt.pth`.

# Acknowledgements

This project is developed upon the following works:

- [UDIS](https://github.com/nie-lang/UnsupervisedDeepImageStitching): For providing UDIS-D dataset.
- [UDIS++](https://github.com/nie-lang/UDIS2): For providing the homography estimator.
- [RAFT](https://github.com/princeton-vl/RAFT): For providing the optical flow estimation backbone.

# References

[1] Lang Nie, Chunyu Lin, Kang Liao, Shuaicheng Liu, and Yao Zhao. Unsupervised deep image stitching: Reconstructing stitched features to images. IEEE transactions on image processing, 30:6184–6197, 2021.

[2] Lang Nie, Chunyu Lin, Kang Liao, Shuaicheng Liu, and Yao Zhao. Parallax-tolerant unsupervised deep image stitching. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 7399–7408, 2023.

[3] Zachary Teed and Jia Deng. Raft: Recurrent all-pairs field transforms for optical flow. In Computer Vision–ECCV 2020: 16th European Conference, Glasgow, UK, August 23– 28, 2020, Proceedings, Part II 16, pages 402–419. Springer, 2020.